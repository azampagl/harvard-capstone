{
 "metadata": {
  "name": "",
  "signature": "sha256:fa49c11af0826976a7715bdf2437be853b250e396d84c0587e7b6a5651528174"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Entries by Day using SVM #"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Setup"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import sys\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "import seaborn as sb\n",
      "import matplotlib, matplotlib.pyplot as plt\n",
      "\n",
      "sys.path.append(\"../\")\n",
      "import features\n",
      "import features.date\n",
      "#import features.entries\n",
      "#import features.station\n",
      "#import features.weather\n",
      "\n",
      "# Setup.\n",
      "% matplotlib inline"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data_daily = pd.read_csv(\"../../../data/mbta_daily.csv\", low_memory=False)\n",
      "data_daily.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>locationid</th>\n",
        "      <th>service_day</th>\n",
        "      <th>entries</th>\n",
        "      <th>name</th>\n",
        "      <th>line_1</th>\n",
        "      <th>line_2</th>\n",
        "      <th>lat</th>\n",
        "      <th>lon</th>\n",
        "      <th>service_datetime</th>\n",
        "      <th>fog</th>\n",
        "      <th>...</th>\n",
        "      <th>entries_weeks_ago_1</th>\n",
        "      <th>entries_weeks_ago_2</th>\n",
        "      <th>entries_weeks_ago_3</th>\n",
        "      <th>rain_predict</th>\n",
        "      <th>rain_fall_predict</th>\n",
        "      <th>snow_predict</th>\n",
        "      <th>snow_fall_predict</th>\n",
        "      <th>snow_accum</th>\n",
        "      <th>snow_accum_predict</th>\n",
        "      <th>dist_to_center</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td> 1002</td>\n",
        "      <td> 2013-01-01 00:00:00</td>\n",
        "      <td> 1892</td>\n",
        "      <td> Andrew Square</td>\n",
        "      <td> Red</td>\n",
        "      <td> NaN</td>\n",
        "      <td> 42.32955</td>\n",
        "      <td>-71.05696</td>\n",
        "      <td> 2013-01-01 03:00:00</td>\n",
        "      <td> 0</td>\n",
        "      <td>...</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 3.404767</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td> 1002</td>\n",
        "      <td> 2013-01-02 00:00:00</td>\n",
        "      <td> 5134</td>\n",
        "      <td> Andrew Square</td>\n",
        "      <td> Red</td>\n",
        "      <td> NaN</td>\n",
        "      <td> 42.32955</td>\n",
        "      <td>-71.05696</td>\n",
        "      <td> 2013-01-02 04:45:00</td>\n",
        "      <td> 0</td>\n",
        "      <td>...</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 3.404767</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td> 1002</td>\n",
        "      <td> 2013-01-03 00:00:00</td>\n",
        "      <td> 5733</td>\n",
        "      <td> Andrew Square</td>\n",
        "      <td> Red</td>\n",
        "      <td> NaN</td>\n",
        "      <td> 42.32955</td>\n",
        "      <td>-71.05696</td>\n",
        "      <td> 2013-01-03 05:00:00</td>\n",
        "      <td> 0</td>\n",
        "      <td>...</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 3.404767</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td> 1002</td>\n",
        "      <td> 2013-01-04 00:00:00</td>\n",
        "      <td> 6125</td>\n",
        "      <td> Andrew Square</td>\n",
        "      <td> Red</td>\n",
        "      <td> NaN</td>\n",
        "      <td> 42.32955</td>\n",
        "      <td>-71.05696</td>\n",
        "      <td> 2013-01-04 05:00:00</td>\n",
        "      <td> 0</td>\n",
        "      <td>...</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 3.404767</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td> 1002</td>\n",
        "      <td> 2013-01-05 00:00:00</td>\n",
        "      <td> 3410</td>\n",
        "      <td> Andrew Square</td>\n",
        "      <td> Red</td>\n",
        "      <td> NaN</td>\n",
        "      <td> 42.32955</td>\n",
        "      <td>-71.05696</td>\n",
        "      <td> 2013-01-05 04:15:00</td>\n",
        "      <td> 0</td>\n",
        "      <td>...</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 3.404767</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "<p>5 rows \u00d7 47 columns</p>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 4,
       "text": [
        "   locationid          service_day  entries           name line_1 line_2  \\\n",
        "0        1002  2013-01-01 00:00:00     1892  Andrew Square    Red    NaN   \n",
        "1        1002  2013-01-02 00:00:00     5134  Andrew Square    Red    NaN   \n",
        "2        1002  2013-01-03 00:00:00     5733  Andrew Square    Red    NaN   \n",
        "3        1002  2013-01-04 00:00:00     6125  Andrew Square    Red    NaN   \n",
        "4        1002  2013-01-05 00:00:00     3410  Andrew Square    Red    NaN   \n",
        "\n",
        "        lat       lon     service_datetime  fog ...   entries_weeks_ago_1  \\\n",
        "0  42.32955 -71.05696  2013-01-01 03:00:00    0 ...                   NaN   \n",
        "1  42.32955 -71.05696  2013-01-02 04:45:00    0 ...                   NaN   \n",
        "2  42.32955 -71.05696  2013-01-03 05:00:00    0 ...                   NaN   \n",
        "3  42.32955 -71.05696  2013-01-04 05:00:00    0 ...                   NaN   \n",
        "4  42.32955 -71.05696  2013-01-05 04:15:00    0 ...                   NaN   \n",
        "\n",
        "   entries_weeks_ago_2  entries_weeks_ago_3  rain_predict  rain_fall_predict  \\\n",
        "0                  NaN                  NaN             0                  0   \n",
        "1                  NaN                  NaN             0                  0   \n",
        "2                  NaN                  NaN             0                  0   \n",
        "3                  NaN                  NaN             0                  0   \n",
        "4                  NaN                  NaN             0                  0   \n",
        "\n",
        "   snow_predict  snow_fall_predict  snow_accum  snow_accum_predict  \\\n",
        "0             0                  0           0                   0   \n",
        "1             0                  0           0                   0   \n",
        "2             0                  0           0                   0   \n",
        "3             0                  0           0                   0   \n",
        "4             1                  0           0                   0   \n",
        "\n",
        "   dist_to_center  \n",
        "0        3.404767  \n",
        "1        3.404767  \n",
        "2        3.404767  \n",
        "3        3.404767  \n",
        "4        3.404767  \n",
        "\n",
        "[5 rows x 47 columns]"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data_raw = pd.read_csv(\"../../../data/mbta.csv\", low_memory=False)\n",
      "data_raw.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>locationid</th>\n",
        "      <th>name</th>\n",
        "      <th>line_1</th>\n",
        "      <th>line_2</th>\n",
        "      <th>lat</th>\n",
        "      <th>lon</th>\n",
        "      <th>entries</th>\n",
        "      <th>exits</th>\n",
        "      <th>service_day</th>\n",
        "      <th>service_datetime</th>\n",
        "      <th>...</th>\n",
        "      <th>snow</th>\n",
        "      <th>temp_min</th>\n",
        "      <th>temp_max</th>\n",
        "      <th>temp_mean</th>\n",
        "      <th>rain_fall</th>\n",
        "      <th>snow_fall</th>\n",
        "      <th>wind_speed</th>\n",
        "      <th>vis_min</th>\n",
        "      <th>vis_max</th>\n",
        "      <th>vis_mean</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td> 1002</td>\n",
        "      <td> Andrew Square</td>\n",
        "      <td> Red</td>\n",
        "      <td> NaN</td>\n",
        "      <td> 42.32955</td>\n",
        "      <td>-71.05696</td>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "      <td> 2013-01-01 00:00:00</td>\n",
        "      <td> 2013-01-01 03:00:00</td>\n",
        "      <td>...</td>\n",
        "      <td> 0</td>\n",
        "      <td> 20</td>\n",
        "      <td> 37</td>\n",
        "      <td> 29</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 14</td>\n",
        "      <td> 10</td>\n",
        "      <td> 10</td>\n",
        "      <td> 10</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td> 1002</td>\n",
        "      <td> Andrew Square</td>\n",
        "      <td> Red</td>\n",
        "      <td> NaN</td>\n",
        "      <td> 42.32955</td>\n",
        "      <td>-71.05696</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "      <td> 2013-01-01 00:00:00</td>\n",
        "      <td> 2013-01-01 05:00:00</td>\n",
        "      <td>...</td>\n",
        "      <td> 0</td>\n",
        "      <td> 20</td>\n",
        "      <td> 37</td>\n",
        "      <td> 29</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 14</td>\n",
        "      <td> 10</td>\n",
        "      <td> 10</td>\n",
        "      <td> 10</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td> 1002</td>\n",
        "      <td> Andrew Square</td>\n",
        "      <td> Red</td>\n",
        "      <td> NaN</td>\n",
        "      <td> 42.32955</td>\n",
        "      <td>-71.05696</td>\n",
        "      <td> 2</td>\n",
        "      <td> 0</td>\n",
        "      <td> 2013-01-01 00:00:00</td>\n",
        "      <td> 2013-01-01 05:15:00</td>\n",
        "      <td>...</td>\n",
        "      <td> 0</td>\n",
        "      <td> 20</td>\n",
        "      <td> 37</td>\n",
        "      <td> 29</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 14</td>\n",
        "      <td> 10</td>\n",
        "      <td> 10</td>\n",
        "      <td> 10</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td> 1002</td>\n",
        "      <td> Andrew Square</td>\n",
        "      <td> Red</td>\n",
        "      <td> NaN</td>\n",
        "      <td> 42.32955</td>\n",
        "      <td>-71.05696</td>\n",
        "      <td> 3</td>\n",
        "      <td> 0</td>\n",
        "      <td> 2013-01-01 00:00:00</td>\n",
        "      <td> 2013-01-01 05:30:00</td>\n",
        "      <td>...</td>\n",
        "      <td> 0</td>\n",
        "      <td> 20</td>\n",
        "      <td> 37</td>\n",
        "      <td> 29</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 14</td>\n",
        "      <td> 10</td>\n",
        "      <td> 10</td>\n",
        "      <td> 10</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td> 1002</td>\n",
        "      <td> Andrew Square</td>\n",
        "      <td> Red</td>\n",
        "      <td> NaN</td>\n",
        "      <td> 42.32955</td>\n",
        "      <td>-71.05696</td>\n",
        "      <td> 6</td>\n",
        "      <td> 0</td>\n",
        "      <td> 2013-01-01 00:00:00</td>\n",
        "      <td> 2013-01-01 05:45:00</td>\n",
        "      <td>...</td>\n",
        "      <td> 0</td>\n",
        "      <td> 20</td>\n",
        "      <td> 37</td>\n",
        "      <td> 29</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 14</td>\n",
        "      <td> 10</td>\n",
        "      <td> 10</td>\n",
        "      <td> 10</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "<p>5 rows \u00d7 23 columns</p>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 5,
       "text": [
        "   locationid           name line_1 line_2       lat       lon  entries  \\\n",
        "0        1002  Andrew Square    Red    NaN  42.32955 -71.05696        0   \n",
        "1        1002  Andrew Square    Red    NaN  42.32955 -71.05696        1   \n",
        "2        1002  Andrew Square    Red    NaN  42.32955 -71.05696        2   \n",
        "3        1002  Andrew Square    Red    NaN  42.32955 -71.05696        3   \n",
        "4        1002  Andrew Square    Red    NaN  42.32955 -71.05696        6   \n",
        "\n",
        "   exits          service_day     service_datetime         ...           snow  \\\n",
        "0      1  2013-01-01 00:00:00  2013-01-01 03:00:00         ...              0   \n",
        "1      0  2013-01-01 00:00:00  2013-01-01 05:00:00         ...              0   \n",
        "2      0  2013-01-01 00:00:00  2013-01-01 05:15:00         ...              0   \n",
        "3      0  2013-01-01 00:00:00  2013-01-01 05:30:00         ...              0   \n",
        "4      0  2013-01-01 00:00:00  2013-01-01 05:45:00         ...              0   \n",
        "\n",
        "   temp_min  temp_max  temp_mean  rain_fall  snow_fall  wind_speed  vis_min  \\\n",
        "0        20        37         29          0          0          14       10   \n",
        "1        20        37         29          0          0          14       10   \n",
        "2        20        37         29          0          0          14       10   \n",
        "3        20        37         29          0          0          14       10   \n",
        "4        20        37         29          0          0          14       10   \n",
        "\n",
        "   vis_max  vis_mean  \n",
        "0       10        10  \n",
        "1       10        10  \n",
        "2       10        10  \n",
        "3       10        10  \n",
        "4       10        10  \n",
        "\n",
        "[5 rows x 23 columns]"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Determine the station of interest.\n",
      "station_raw = data_raw[data_raw[\"locationid\"] == 1002]\n",
      "\n",
      "# Keep only weekdays.\n",
      "station_raw = station_raw[(pd.DatetimeIndex(station_raw['service_day']).weekday != 5) & (pd.DatetimeIndex(station_raw['service_day']).weekday != 6)]\n",
      "\n",
      "# Drop unecessary columns.\n",
      "station_raw = station_raw[['locationid', 'service_day', 'service_datetime', 'entries']]\n",
      "\n",
      "# Add station time field.\n",
      "station_raw = features.date.init(station_raw)\n",
      "station_raw = features.date.add_service_minutes_fraction(station_raw)\n",
      "station_raw.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>locationid</th>\n",
        "      <th>service_day</th>\n",
        "      <th>service_datetime</th>\n",
        "      <th>entries</th>\n",
        "      <th>service_minutes_fraction</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td> 1002</td>\n",
        "      <td>2013-01-01</td>\n",
        "      <td>2013-01-01 03:00:00</td>\n",
        "      <td> 0</td>\n",
        "      <td> 3.00</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td> 1002</td>\n",
        "      <td>2013-01-01</td>\n",
        "      <td>2013-01-01 05:00:00</td>\n",
        "      <td> 1</td>\n",
        "      <td> 5.00</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td> 1002</td>\n",
        "      <td>2013-01-01</td>\n",
        "      <td>2013-01-01 05:15:00</td>\n",
        "      <td> 2</td>\n",
        "      <td> 5.25</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td> 1002</td>\n",
        "      <td>2013-01-01</td>\n",
        "      <td>2013-01-01 05:30:00</td>\n",
        "      <td> 3</td>\n",
        "      <td> 5.50</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td> 1002</td>\n",
        "      <td>2013-01-01</td>\n",
        "      <td>2013-01-01 05:45:00</td>\n",
        "      <td> 6</td>\n",
        "      <td> 5.75</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 24,
       "text": [
        "   locationid service_day    service_datetime  entries  \\\n",
        "0        1002  2013-01-01 2013-01-01 03:00:00        0   \n",
        "1        1002  2013-01-01 2013-01-01 05:00:00        1   \n",
        "2        1002  2013-01-01 2013-01-01 05:15:00        2   \n",
        "3        1002  2013-01-01 2013-01-01 05:30:00        3   \n",
        "4        1002  2013-01-01 2013-01-01 05:45:00        6   \n",
        "\n",
        "   service_minutes_fraction  \n",
        "0                      3.00  \n",
        "1                      5.00  \n",
        "2                      5.25  \n",
        "3                      5.50  \n",
        "4                      5.75  "
       ]
      }
     ],
     "prompt_number": 24
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "grouped = station_raw.groupby(['locationid', 'service_day', 'service_minutes_fraction'], as_index=False)\n",
      "station = grouped.agg(np.mean)\n",
      "station.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>locationid</th>\n",
        "      <th>service_day</th>\n",
        "      <th>service_minutes_fraction</th>\n",
        "      <th>entries</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td> 1002</td>\n",
        "      <td>2013-01-01</td>\n",
        "      <td> 0.00</td>\n",
        "      <td> 10</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td> 1002</td>\n",
        "      <td>2013-01-01</td>\n",
        "      <td> 0.25</td>\n",
        "      <td>  7</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td> 1002</td>\n",
        "      <td>2013-01-01</td>\n",
        "      <td> 0.50</td>\n",
        "      <td>  1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td> 1002</td>\n",
        "      <td>2013-01-01</td>\n",
        "      <td> 1.00</td>\n",
        "      <td>  1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td> 1002</td>\n",
        "      <td>2013-01-01</td>\n",
        "      <td> 1.25</td>\n",
        "      <td>  1</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 22,
       "text": [
        "   locationid service_day  service_minutes_fraction  entries\n",
        "0        1002  2013-01-01                      0.00       10\n",
        "1        1002  2013-01-01                      0.25        7\n",
        "2        1002  2013-01-01                      0.50        1\n",
        "3        1002  2013-01-01                      1.00        1\n",
        "4        1002  2013-01-01                      1.25        1"
       ]
      }
     ],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(\"Original: \" + str(len(data)))\n",
      "\n",
      "data = data[(pd.DatetimeIndex(data['service_day']).weekday != 5) & (pd.DatetimeIndex(data['service_day']).weekday != 6)]\n",
      "\n",
      "print(\"Remaining: \" + str(len(data)))\n",
      "data.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Original: 47901\n",
        "Remaining: 34294"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>locationid</th>\n",
        "      <th>service_day</th>\n",
        "      <th>entries</th>\n",
        "      <th>name</th>\n",
        "      <th>line_1</th>\n",
        "      <th>line_2</th>\n",
        "      <th>lat</th>\n",
        "      <th>lon</th>\n",
        "      <th>service_datetime</th>\n",
        "      <th>fog</th>\n",
        "      <th>...</th>\n",
        "      <th>entries_weeks_ago_1</th>\n",
        "      <th>entries_weeks_ago_2</th>\n",
        "      <th>entries_weeks_ago_3</th>\n",
        "      <th>rain_predict</th>\n",
        "      <th>rain_fall_predict</th>\n",
        "      <th>snow_predict</th>\n",
        "      <th>snow_fall_predict</th>\n",
        "      <th>snow_accum</th>\n",
        "      <th>snow_accum_predict</th>\n",
        "      <th>dist_to_center</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td> 1002</td>\n",
        "      <td> 2013-01-01 00:00:00</td>\n",
        "      <td> 1892</td>\n",
        "      <td> Andrew Square</td>\n",
        "      <td> Red</td>\n",
        "      <td> NaN</td>\n",
        "      <td> 42.32955</td>\n",
        "      <td>-71.05696</td>\n",
        "      <td> 2013-01-01 03:00:00</td>\n",
        "      <td> 0</td>\n",
        "      <td>...</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 3.404767</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td> 1002</td>\n",
        "      <td> 2013-01-02 00:00:00</td>\n",
        "      <td> 5134</td>\n",
        "      <td> Andrew Square</td>\n",
        "      <td> Red</td>\n",
        "      <td> NaN</td>\n",
        "      <td> 42.32955</td>\n",
        "      <td>-71.05696</td>\n",
        "      <td> 2013-01-02 04:45:00</td>\n",
        "      <td> 0</td>\n",
        "      <td>...</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 3.404767</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td> 1002</td>\n",
        "      <td> 2013-01-03 00:00:00</td>\n",
        "      <td> 5733</td>\n",
        "      <td> Andrew Square</td>\n",
        "      <td> Red</td>\n",
        "      <td> NaN</td>\n",
        "      <td> 42.32955</td>\n",
        "      <td>-71.05696</td>\n",
        "      <td> 2013-01-03 05:00:00</td>\n",
        "      <td> 0</td>\n",
        "      <td>...</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 3.404767</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td> 1002</td>\n",
        "      <td> 2013-01-04 00:00:00</td>\n",
        "      <td> 6125</td>\n",
        "      <td> Andrew Square</td>\n",
        "      <td> Red</td>\n",
        "      <td> NaN</td>\n",
        "      <td> 42.32955</td>\n",
        "      <td>-71.05696</td>\n",
        "      <td> 2013-01-04 05:00:00</td>\n",
        "      <td> 0</td>\n",
        "      <td>...</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 3.404767</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>6</th>\n",
        "      <td> 1002</td>\n",
        "      <td> 2013-01-07 00:00:00</td>\n",
        "      <td> 5998</td>\n",
        "      <td> Andrew Square</td>\n",
        "      <td> Red</td>\n",
        "      <td> NaN</td>\n",
        "      <td> 42.32955</td>\n",
        "      <td>-71.05696</td>\n",
        "      <td> 2013-01-07 04:00:00</td>\n",
        "      <td> 0</td>\n",
        "      <td>...</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 3.404767</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "<p>5 rows \u00d7 47 columns</p>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 3,
       "text": [
        "   locationid          service_day  entries           name line_1 line_2  \\\n",
        "0        1002  2013-01-01 00:00:00     1892  Andrew Square    Red    NaN   \n",
        "1        1002  2013-01-02 00:00:00     5134  Andrew Square    Red    NaN   \n",
        "2        1002  2013-01-03 00:00:00     5733  Andrew Square    Red    NaN   \n",
        "3        1002  2013-01-04 00:00:00     6125  Andrew Square    Red    NaN   \n",
        "6        1002  2013-01-07 00:00:00     5998  Andrew Square    Red    NaN   \n",
        "\n",
        "        lat       lon     service_datetime  fog ...   entries_weeks_ago_1  \\\n",
        "0  42.32955 -71.05696  2013-01-01 03:00:00    0 ...                   NaN   \n",
        "1  42.32955 -71.05696  2013-01-02 04:45:00    0 ...                   NaN   \n",
        "2  42.32955 -71.05696  2013-01-03 05:00:00    0 ...                   NaN   \n",
        "3  42.32955 -71.05696  2013-01-04 05:00:00    0 ...                   NaN   \n",
        "6  42.32955 -71.05696  2013-01-07 04:00:00    0 ...                   NaN   \n",
        "\n",
        "   entries_weeks_ago_2  entries_weeks_ago_3  rain_predict  rain_fall_predict  \\\n",
        "0                  NaN                  NaN             0                  0   \n",
        "1                  NaN                  NaN             0                  0   \n",
        "2                  NaN                  NaN             0                  0   \n",
        "3                  NaN                  NaN             0                  0   \n",
        "6                  NaN                  NaN             0                  0   \n",
        "\n",
        "   snow_predict  snow_fall_predict  snow_accum  snow_accum_predict  \\\n",
        "0             0                  0           0                   0   \n",
        "1             0                  0           0                   0   \n",
        "2             0                  0           0                   0   \n",
        "3             0                  0           0                   0   \n",
        "6             0                  0           0                   0   \n",
        "\n",
        "   dist_to_center  \n",
        "0        3.404767  \n",
        "1        3.404767  \n",
        "2        3.404767  \n",
        "3        3.404767  \n",
        "6        3.404767  \n",
        "\n",
        "[5 rows x 47 columns]"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "\"\"\"\n",
      "def predict(station, x_cols, predictor, parameters, ape_threshold, state, drop_outliers = False):\n",
      "    # Copy the station so we don't manipulate the original\n",
      "    station = station.copy()\n",
      "    \n",
      "    # Get the columns of the dataframe.\n",
      "    cols = list(station.columns)\n",
      "    \n",
      "    # Determine the indices of the columns.\n",
      "    y_col_indices = [0] + list(np.where([col == 'entries' for col in cols])[0] + 1)\n",
      "    x_col_indices = [0] + list(np.where([col in x_cols for col in cols])[0] + 1)\n",
      "    \n",
      "    # Make sure none of the predictor fields are null.\n",
      "    for col in x_cols:\n",
      "        station = station[pd.notnull(station[col])]\n",
      "    \n",
      "    # Remove any entries where no one was there...\n",
      "    station = station[station['entries'] > 50]\n",
      "    \n",
      "    # Reset the station indices, we have to reset twice so the matrix values gets the index column.\n",
      "    station = station.reset_index()\n",
      "    station.drop('index', axis=1, inplace=True)\n",
      "    station = station.reset_index()\n",
      "    \n",
      "    # Get the dataframe as a matrix where the first column is the index.\n",
      "    matrix = station.values\n",
      "    \n",
      "    # Slice so the y only contains 2 column (index, entries)\n",
      "    #  and the x is a matrix that contains the index and all the predictors.\n",
      "    y = matrix[:,y_col_indices]\n",
      "    x = matrix[:,x_col_indices]\n",
      "    \n",
      "    # Split the data set into a train and test.\n",
      "    x_train, x_test, y_train, y_test = cross_validation.train_test_split(x, y, test_size=0.2, random_state=state)\n",
      "    \n",
      "    # Convert the train and test sets into a format sklean fit() expects.\n",
      "    x_train_fit = np.matrix(x_train[:,1:], dtype=np.float32)\n",
      "    y_train_fit = np.array([v[0] for v in y_train[:,1:]], dtype=np.uint16)\n",
      "    \n",
      "    x_test_fit = np.matrix(x_test[:,1:], dtype=np.float32)\n",
      "    y_test_fit = np.array([v[0] for v in y_test[:,1:]], dtype=np.uint16)\n",
      "    \n",
      "    # Train using a grid search based on the parameters provided.\n",
      "    clf = grid_search.GridSearchCV(predictor, parameters, scoring='mean_squared_error', cv=10)\n",
      "    clf.fit(x_train_fit, y_train_fit)\n",
      "    \n",
      "    # Determine what the best model was.\n",
      "    model = clf.best_estimator_\n",
      "    \n",
      "    # Predict using the test set.\n",
      "    y_pred_fit = model.predict(x_test_fit)\n",
      "    \n",
      "    # Determine the absolute percent errors.\n",
      "    apes = np.abs(y_pred_fit - y_test_fit) / y_test_fit\n",
      "    \n",
      "    # Determine any \"extreme\" outliers by determining large percent errors.\n",
      "    ape_indices = apes >= ape_threshold\n",
      "    outlier_indices = y_test[ape_indices][:,0]\n",
      "    outliers = station.iloc[outlier_indices]\n",
      "    outliers['entries_predicted'] = y_pred_fit[ape_indices]\n",
      "    outliers['entries_ape'] = apes[ape_indices]\n",
      "    \n",
      "    # Remove any percent difference that would cause an error in calculating the mean.\n",
      "    apes = apes[apes < float('+inf')]\n",
      "    if (drop_outliers):\n",
      "        apes = apes[apes < ape_threshold]\n",
      "    \n",
      "    return model, apes, outliers"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def find_outliers(station, x_cols, model):\n",
      "    outliers = pd.DataFrame()\n",
      "\n",
      "    for index, row in station.iterrows():\n",
      "        y = row['entries']\n",
      "        x = row.as_matrix(x_cols)\n",
      "        \n",
      "        nan = False\n",
      "        for i in x:\n",
      "            if np.isnan(i):\n",
      "                nan= True\n",
      "                break\n",
      "        if nan:\n",
      "            continue\n",
      "        \n",
      "        y_pred = model.predict(x)\n",
      "\n",
      "        ape = np.abs(y_pred[0] - y) / y\n",
      "\n",
      "        if (ape > .2):\n",
      "            row['entries_predict'] = y_pred[0]\n",
      "            row['entries_ape'] = ape\n",
      "\n",
      "            outliers = outliers.append(row)\n",
      "    \n",
      "    return outliers"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def features_test(stationids, x_cols):\n",
      "    accuracies = []\n",
      "    for stationid in stationids:\n",
      "        station = data[data['locationid'] == stationid]\n",
      "\n",
      "        #predictor = svm.SVR()\n",
      "        #parameters = {'kernel': ('linear', 'rbf'), 'C': range(1, 2)}\n",
      "        predictor = linear_model.LinearRegression()\n",
      "        parameters = {}\n",
      "        \n",
      "        # Train and predict X times, each with a different train/test set using a random state.\n",
      "        mean_apes = []\n",
      "        for state in xrange(10):\n",
      "            model, apes, outliers = predict(station, x_cols, predictor, parameters, .2, state, False)\n",
      "            #outliers.to_csv(\"outliers-tmp-\" + str(stationid) + \".csv\", index=False)\n",
      "            #print(np.mean(apes))\n",
      "            mean_apes.append(np.mean(apes))\n",
      "\n",
      "        #outliers = find_outliers(station, x_cols, model)\n",
      "        #outliers.to_csv(\"outliers-\" + str(stationid) + \".csv\", index=False)\n",
      "        \n",
      "        accuracies.append(1 - np.mean(mean_apes))\n",
      "        \n",
      "        print(station.iloc[0][\"name\"] + \": \" + str(accuracies[-1]))\n",
      "    \n",
      "    return accuracies"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "stationids = [\n",
      "    1020, # Braintree\n",
      "    1032, # Alewife\n",
      "    1035, # Harvard\n",
      "    1039, # Downtown\n",
      "    1043, # Ashmont\n",
      "    1059, # Kenmore\n",
      "    1075, # North\n",
      "]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "accuracies = features_test(stationids, ['day_of_week_0', 'day_of_week_1', 'day_of_week_2', 'day_of_week_3', 'day_of_week_4', 'entries_weeks_ago_1'])\n",
      "print(\"Mean: \" + str(np.mean(accuracies)))\n",
      "print(\"Var: \" + str(np.var(accuracies)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Braintree: 0.808034659935\n",
        "Alewife: 0.788160579355"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Harvard: 0.839382219935"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Downtown Crossing: 0.40920319469"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Ashmont: 0.830318999826"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Kenmore Square: 0.753261113394"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "North Station: 0.711843092591"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Mean: 0.734314837104\n",
        "Var: 0.0193073501645\n"
       ]
      }
     ],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "accuracies = features_test(stationids, ['day_of_week_0', 'day_of_week_1', 'day_of_week_2', 'day_of_week_3', 'day_of_week_4', 'entries_weeks_ago_1', 'snow_fall'])\n",
      "print(\"Mean: \" + str(np.mean(accuracies)))\n",
      "print(\"Var: \" + str(np.var(accuracies)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Braintree: 0.824133935605\n",
        "Alewife: 0.802462865258"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Harvard: 0.851474464359"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Downtown Crossing: 0.619149123287"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Ashmont: 0.846935852425"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Kenmore Square: 0.759737629477"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "North Station: 0.716187723508"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Mean: 0.77429737056\n",
        "Var: 0.00602418956212\n"
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "accuracies = features_test(stationids, ['day_of_week_0', 'day_of_week_1', 'day_of_week_2', 'day_of_week_3', 'day_of_week_4', 'entries_weeks_ago_1', 'snow'])\n",
      "print(\"Mean: \" + str(np.mean(accuracies)))\n",
      "print(\"Var: \" + str(np.var(accuracies)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Braintree: 0.813675263564\n",
        "Alewife: 0.792026420638"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Harvard: 0.841790863532"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Downtown Crossing: 0.447795204618"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Ashmont: 0.829769979854"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Kenmore Square: 0.747992851847"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "North Station: 0.711130771263"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Mean: 0.740597336474\n",
        "Var: 0.0161190407006\n"
       ]
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "accuracies = features_test(stationids, ['day_of_week_0', 'day_of_week_1', 'day_of_week_2', 'day_of_week_3', 'day_of_week_4', 'entries_weeks_ago_1', 'snow_accum'])\n",
      "print(\"Mean: \" + str(np.mean(accuracies)))\n",
      "print(\"Var: \" + str(np.var(accuracies)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Braintree: 0.82811880225\n",
        "Alewife: 0.802076521309"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Harvard: 0.849448148284"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Downtown Crossing: 0.59284369088"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Ashmont: 0.843927997629"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Kenmore Square: 0.755765634107"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "North Station: 0.712857503969"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Mean: 0.76929118549\n",
        "Var: 0.00729039692191\n"
       ]
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "accuracies = features_test(stationids, ['day_of_week_0', 'day_of_week_1', 'day_of_week_2', 'day_of_week_3', 'day_of_week_4', 'entries_weeks_ago_1', 'snow_fall', 'snow_accum'])\n",
      "print(\"Mean: \" + str(np.mean(accuracies)))\n",
      "print(\"Var: \" + str(np.var(accuracies)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Braintree: 0.82795100997\n",
        "Alewife: 0.802781192496"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Harvard: 0.851274557388"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Downtown Crossing: 0.629702943666"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Ashmont: 0.845384386198"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Kenmore Square: 0.756059891016"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "North Station: 0.715182116487"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Mean: 0.775476585317\n",
        "Var: 0.00562770365706\n"
       ]
      }
     ],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}